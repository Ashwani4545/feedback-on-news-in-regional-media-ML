# ğŸ“˜ Regional Newsroom Feedback System (AI + Twitter/X Integration)

---

# ğŸ“° Overview

This project aims to analyze audience feedback for regional news outlets using AI/ML techniques.
It collects audience reactions from multiple channels â€” especially Twitter/X â€” and generates actionable insights to improve content relevance, credibility, and community trust.

The system automatically:
â€¢ Fetches tweets via Twitter/X API (v2)
â€¢ Analyzes sentiment, urgency, and correction indicators using NLP
â€¢ Stores and manages data in a structured SQL database
â€¢ Displays insights through an interactive Streamlit dashboard

---

# âš™ï¸ Features
```
âœ… Collect regional news feedback via Twitter/X APIs
âœ… Store structured feedback using SQLAlchemy + SQLite
âœ… Perform sentiment & urgency analysis (VADER NLP)
âœ… RESTful Flask backend APIs
âœ… Streamlit dashboard for visualization
âœ… Optional Dockerized environment
âœ… CI-ready with GitHub Actions
```
---

# ğŸ§° Tech Stack
```
Layer Technology

Backend Python (Flask)

NLP/ML NLTK (VADER), scikit-learn

Database SQLite (upgradeable to MySQL/PostgreSQL)

Frontend Streamlit

External APIs Twitter/X API v2

CI/CD GitHub Actions

Deployment Docker, Docker Compose
```
---

# ğŸ§© Folder Structure
```
regional_feedback_full/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # Flask API server
â”‚ â”œâ”€â”€ twitter_etl.py # Fetch feedback from Twitter/X
â”‚ â”œâ”€â”€ analysis.py # NLP-based sentiment and correction detection
â”‚ â”œâ”€â”€ database.py # SQLAlchemy models and DB initialization
â”‚
â”œâ”€â”€ dashboard/
â”‚ â””â”€â”€ streamlit_app.py # Streamlit dashboard
â”‚
â”œâ”€â”€ tests/ # Unit tests
|
â”œâ”€â”€ .github/workflows/ci.yml # GitHub Actions workflow
â”œâ”€â”€ docker-compose.yml # Multi-service (API + dashboard)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```
---
# ğŸ§± Environment Setup

1ï¸âƒ£ Clone or Unzip Project
```
unzip regional_feedback_full.zip
cd regional_feedback_full
```

2ï¸âƒ£ Create Virtual Environment
```
Windows:
python -m venv venv
venv\Scripts\activate
macOS / Linux:
python3 -m venv venv
source venv/bin/activate
```

3ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```

4ï¸âƒ£ Configure Environment Variables
```
Copy and edit the .env file:
cp .env.example .env
Then open .env and set your credentials:
TWITTER_BEARER_TOKEN=your_actual_twitter_api_bearer_token
DATABASE_URL=sqlite:///./data/feedback.db
API_PORT=8000
```
---

# ğŸ—ƒï¸ Database Initialization

python -m app.database

---

# ğŸš€ Run the Application

â–¶ï¸ Run Flask API
```
python -m app.main
Access it at: http://localhost:8000
```

â–¶ï¸ Fetch Tweets from Twitter/X
```
Open another terminal and run:
python -m app.twitter_etl --query "#BanarasNews -is:retweet lang:en"
```
---

ğŸ“Š Open Streamlit Dashboard

streamlit run dashboard/streamlit_app.py
Dashboard URL â†’ http://localhost:8501
You can:
â€¢ View urgent or corrective feedback posts
â€¢ Inspect sentiment analysis results
â€¢ Track new audience reactions

---

ğŸ³ Docker Setup (Optional)

If you prefer running everything in containers:
docker-compose up --build
This will launch:
â€¢ Flask API: http://localhost:8000
â€¢ Streamlit Dashboard: http://localhost:8501

---

ğŸ§ª Run Tests

pytest -q

---

# ğŸ§  Example API Request

curl -X POST http://localhost:8000/ingest_manual \
 -H "Content-Type: application/json" \
 -d '{"raw_text": "Please correct the statistics in todayâ€™s report", "channel": "email"}'

---

# ğŸ§¾ Future Enhancements

â€¢ Advanced topic classification (TF-IDF + Logistic Regression)
â€¢ Multi-channel integration (YouTube, Facebook)
â€¢ Role-based authentication for newsroom staff
â€¢ Data visualization enhancements (word clouds, timelines)

---

# ğŸ§‘â€ğŸ’» Maintainer

Developed by: Ashwani Pandey
Tech Stack: Python Â· Flask Â· SQLAlchemy Â· Streamlit Â· Docker Â· Twitter API
